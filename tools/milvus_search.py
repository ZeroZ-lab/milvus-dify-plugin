from typing import Any, List, Dict, Optional
from collections.abc import Generator
import json
import logging

from dify_plugin import Tool
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin.entities.model.text_embedding import TextEmbeddingModelConfig
from dify_plugin.entities.model import ModelType
from .milvus_base import MilvusBaseTool

logger = logging.getLogger(__name__)

class MilvusSearchTool(MilvusBaseTool, Tool):
    """Milvus å‘é‡æœç´¢å·¥å…·"""

    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage, None, None]:
        """æ‰§è¡Œæœç´¢å·¥å…·"""
        try:
            # è§£æå’ŒéªŒè¯å‚æ•°
            collection_name = tool_parameters.get("collection_name")
            vector_str = tool_parameters.get("query_vector")
            query_text = tool_parameters.get("query_text")
            embedding_model = tool_parameters.get("embedding_model")

            if not collection_name or not self._validate_collection_name(collection_name):
                raise ValueError("Invalid or missing collection name.")

            # æ£€æŸ¥æ˜¯å¦è‡³å°‘æä¾›äº†ä¸€ç§æŸ¥è¯¢æ–¹å¼
            if not vector_str and not query_text:
                raise ValueError("Either query vector or query text is required.")

            # å¦‚æœæä¾›äº†æŸ¥è¯¢æ–‡æœ¬ï¼Œåˆ™å°†å…¶è½¬æ¢ä¸ºå‘é‡
            if query_text:
                # æ£€æŸ¥æ˜¯å¦æä¾›äº†åµŒå…¥æ¨¡å‹
                if not embedding_model and query_text:
                    raise ValueError("Embedding model is required when using query text.")
                
                logger.info(f"ğŸ”¤ [INFO] Converting query text to vector: '{query_text[:50]}...'")
                vector_data = self._text_to_embedding(query_text, embedding_model)
            else:
                # å¦åˆ™è§£ææä¾›çš„å‘é‡æ•°æ®
                try:
                    vector_data = self._parse_vector_data(str(vector_str))
                except ValueError as e:
                    raise ValueError(str(e))

            # è·å–å…¶ä»–å‚æ•°
            limit = int(tool_parameters.get("limit", 10))
            output_fields_str = tool_parameters.get("output_fields")
            filter_expr = tool_parameters.get("filter")
            search_params_str = tool_parameters.get("search_params")
            anns_field = tool_parameters.get("anns_field", "vector")

            # å‡†å¤‡å‚æ•°
            search_params = self._parse_search_params(search_params_str)
            output_fields = [f.strip() for f in output_fields_str.split(',')] if output_fields_str else None

            # æ‰§è¡Œæœç´¢
            with self._get_milvus_client(self.runtime.credentials) as client:
                if not client.has_collection(collection_name):
                    raise ValueError(f"Collection '{collection_name}' does not exist.")

                logger.info(f"ğŸ” [DEBUG] Searching in collection '{collection_name}' with limit={limit}, anns_field='{anns_field}'")

                results = client.search(
                    collection_name=collection_name,
                    data=[vector_data],
                    anns_field=anns_field,
                    limit=limit,
                    output_fields=output_fields,
                    filter=filter_expr,
                    search_params=search_params,
                    partition_names=None # partition_names not supported in this tool
                )

                logger.info(f"âœ… [DEBUG] Search completed. Found {len(results)} results.")
                
                response_data = {
                    "operation": "search",
                    "collection_name": collection_name,
                    "results": results,
                    "result_count": len(results)
                }
                yield from self._create_success_message(response_data)

        except Exception as e:
            yield from self._handle_error(e)

    def _handle_error(self, error: Exception) -> Generator[ToolInvokeMessage, None, None]:
        """ç»Ÿä¸€çš„é”™è¯¯å¤„ç†"""
        error_msg = str(error)
        yield self.create_json_message({
            "success": False,
            "error": error_msg,
            "error_type": type(error).__name__
        })

    def _create_success_message(self, data: dict[str, Any]) -> Generator[ToolInvokeMessage, None, None]:
        """åˆ›å»ºæˆåŠŸå“åº”æ¶ˆæ¯"""
        response = {
            "success": True,
            **data
        }
        yield self.create_json_message(response)
        
    def _text_to_embedding(self, text: str, model_info: Any) -> List[float]:
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºåµŒå…¥å‘é‡
        
        ä½¿ç”¨Difyå¹³å°æä¾›çš„æ–‡æœ¬åµŒå…¥åŠŸèƒ½å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ã€‚
        æ ¹æ®manifest.yamlä¸­é…ç½®çš„text-embeddingæƒé™ï¼ŒDifyä¼šè‡ªåŠ¨æä¾›åµŒå…¥åŠŸèƒ½ã€‚
        
        Args:
            text: è¦è½¬æ¢ä¸ºå‘é‡çš„æ–‡æœ¬
            model_info: åµŒå…¥æ¨¡å‹ä¿¡æ¯
        
        Returns:
            åµŒå…¥å‘é‡ï¼Œè¡¨ç¤ºä¸ºæµ®ç‚¹æ•°åˆ—è¡¨
        """
        try:
            logger.info(f"ğŸ“Š [INFO] è¯·æ±‚æ–‡æœ¬åµŒå…¥ï¼Œæ–‡æœ¬: '{text[:30]}...'")
            logger.info(f"ğŸ”§ [INFO] ä½¿ç”¨æŒ‡å®šçš„åµŒå…¥æ¨¡å‹: {model_info}")
            
            # ä»model_infoä¸­æå–æ¨¡å‹åç§°
            model_name = ""
            provider = ""
            
            if isinstance(model_info, dict):
                # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•è·å–modelå­—æ®µ
                if "model" in model_info:
                    model_name = model_info["model"]
                # å°è¯•è·å–providerå­—æ®µ
                if "provider" in model_info:
                    provider = model_info["provider"]
            else:
                # å¦åˆ™ç›´æ¥ä½¿ç”¨model_infoä½œä¸ºæ¨¡å‹åç§°
                model_name = str(model_info)
            
            # å¦‚æœæ²¡æœ‰æä¾›providerï¼Œä½¿ç”¨é»˜è®¤å€¼
            if not provider:
                provider = "default"
                
            logger.info(f"ğŸ”§ [INFO] æå–çš„æ¨¡å‹åç§°: {model_name}, æä¾›è€…: {provider}")
            
            # åˆ›å»ºTextEmbeddingModelConfig
            model_config = TextEmbeddingModelConfig(
                model=model_name,
                provider=provider,
                model_type=ModelType.TEXT_EMBEDDING
            )
            
            logger.info(f"ğŸ”§ [INFO] åˆ›å»ºçš„æ¨¡å‹é…ç½®: {model_config}")
            
            # è°ƒç”¨text_embedding.invokeæ–¹æ³•
            embedding_result = self.session.model.text_embedding.invoke(
                model_config=model_config,
                texts=[text]
            )
            
            logger.info(f"âœ… [INFO] åµŒå…¥ç»“æœç±»å‹: {type(embedding_result)}")
            
            # æ£€æŸ¥ç»“æœ
            if embedding_result and hasattr(embedding_result, 'embeddings') and embedding_result.embeddings:
                # è·å–ç¬¬ä¸€ä¸ªæ–‡æœ¬çš„åµŒå…¥å‘é‡
                embedding_vector = embedding_result.embeddings[0]
                logger.info(f"âœ… [INFO] æˆåŠŸç”ŸæˆåµŒå…¥å‘é‡ï¼Œç»´åº¦: {len(embedding_vector)}")
                return embedding_vector
            else:
                logger.error("âŒ [ERROR] åµŒå…¥ç»“æœä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡® (Debug for ai)")
                raise ValueError("æ— æ³•ä¸ºæ–‡æœ¬ç”ŸæˆåµŒå…¥å‘é‡: ç»“æœä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
            
        except Exception as e:
            logger.error(f"âŒ [ERROR] æ–‡æœ¬åµŒå…¥å¤±è´¥: {str(e)}")
            raise ValueError(f"æ–‡æœ¬åµŒå…¥è½¬æ¢å¤±è´¥: {str(e)}")